{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb의 사본",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1GjN5yb70H_",
        "colab_type": "code",
        "outputId": "57268c5f-538e-4ce5-e0ba-a9dcaa8b21fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYTC9FXd8ew4",
        "colab_type": "code",
        "outputId": "aa870e79-bac9-446a-f255-df7ccb5fb5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.layers.core import Dense, Flatten,  Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import gzip\n",
        "import os\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tU7w4uE8jxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_data(dirname, csvname):\n",
        "    with open(filepath, 'ab') as f:\n",
        "      data = []\n",
        "      csv = pd.read_csv(csvname, sep=',')\n",
        "      joy_values = csv['wheel'].values.tolist()\n",
        "      images = glob.glob(dirname)\n",
        "      count = 0\n",
        "      for img in images:\n",
        "          screenshot = cv2.imread(img)\n",
        "          if count < len(joy_values):\n",
        "              screenshot = transform_image(np.array(screenshot))\n",
        "              data.append([screenshot, joy_values[count]])\n",
        "          if count == len(images) - 1:\n",
        "              print('Collected data count - {0}.'.format(count))\n",
        "              pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
        "              data = [] \n",
        "          count += 1\n",
        "def read_data(split=False):\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        data = []\n",
        "        while True:\n",
        "            try:\n",
        "                temp = pickle.load(f)\n",
        "                if type(temp) is not list:\n",
        "                    temp = np.ndarray.tolist(temp)\n",
        "                data = data + temp\n",
        "            except EOFError:\n",
        "                break\n",
        "        if split:\n",
        "            x_train = []\n",
        "            y_train = []\n",
        "\n",
        "            for i in range(0, len(data)):\n",
        "                x_train.append(data[i][0])\n",
        "                y_train.append(data[i][1])\n",
        "\n",
        "            return np.array(x_train), np.array(y_train)\n",
        "        else:\n",
        "            return np.array(data)\n",
        "\n",
        "def create_model():\n",
        "    base_mobilenet_model = MobileNetV2(input_shape =  (100,400,3), \n",
        "                                    include_top = False, \n",
        "                                    weights = None,\n",
        "                                     alpha=0.6)\n",
        "    pilot_model = Sequential()\n",
        "    pilot_model.add(BatchNormalization(input_shape =(100,400,3)))\n",
        "    pilot_model.add(base_mobilenet_model)\n",
        "    pilot_model.add(BatchNormalization())\n",
        "    pilot_model.add(GlobalAveragePooling2D())\n",
        "    pilot_model.add(Dropout(0.5))\n",
        "    pilot_model.add(Dense(1, activation = 'linear' )) # linear is what 16bit did\n",
        "\n",
        "    pilot_model.summary()\n",
        "\n",
        "    pilot_model.compile(loss=keras.losses.mean_squared_error,\n",
        "                  optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "                  metrics=[sign_pred])\n",
        "    return pilot_model\n",
        "\n",
        "def get_model():\n",
        "    if os.path.isfile(modelpath):\n",
        "        model = keras.models.load_model(modelpath)\n",
        "    else:\n",
        "        model = create_model()\n",
        "    return model\n",
        "\n",
        "def sign_pred(y_true, y_pred):\n",
        "    mult = y_true * y_pred\n",
        "    eq = keras.backend.cast(keras.backend.equal(keras.backend.sign(mult),keras.backend.ones_like(mult)), 'int32')\n",
        "    return keras.backend.sum(eq) \n",
        "\n",
        "def train_model(model):\n",
        "    x, y = read_data(True)\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, random_state=444)\n",
        "\n",
        "    # test data set 0.15 : training data set 85%\n",
        "    checkpoint = ModelCheckpoint('model-{epoch:03d}.h5', monitor='val_loss', verbose=1,save_best_only=True, mode='min')\n",
        "    earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=80)\n",
        "    model.fit_generator(DataGenerator(x_train, y_train, 64, (100, 400), 3), steps_per_epoch= len(x_train)/64, epochs=200,\n",
        "              validation_data=DataGenerator(x_valid, y_valid, 64, (100, 400), 3), validation_steps=len(y_valid)/64, callbacks=[checkpoint,earlystop], verbose=1)\n",
        "    model.save(modelpath)\n",
        "\n",
        "def display_data():\n",
        "    data = read_data()\n",
        "    data_size = len(data)\n",
        "    print('Data size  -  ' + str(data_size))\n",
        "\n",
        "    for i in range(data_size - 1, 0, -1):\n",
        "        print(str(image[1]))\n",
        "        cv2.waitKey(50)\n",
        "\n",
        "def display(image, angle, label):\n",
        "    plt.imshow(image)\n",
        "    plt.xlabel(\"Steering angle: {:.10f}\".format(angle))\n",
        "    plt.title(label)\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, X, y, batch_size, dim, n_channels, shuffle = True):\n",
        "        self.X = X\n",
        "        self.y = y if y is not None else y\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.X) / self.batch_size))\n",
        "    \n",
        "    def __data_generation(self, X_list, y_list):\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size))\n",
        "        range_x = 50\n",
        "        if y is not None:\n",
        "            for i, (image, wheel) in enumerate(zip(X_list, y_list)):\n",
        "                image = image / 255.0\n",
        "                if np.random.rand() < 0.5:\n",
        "                    image = cv2.flip(image, 1)\n",
        "                    wheel = -wheel\n",
        "                if np.random.rand() < 0.5:\n",
        "                    trans_x = range_x * (np.random.rand() - 0.5)\n",
        "                    wheel += trans_x * 0.01\n",
        "                    trans_m = np.float32([[1, 0, trans_x], [0, 1, 0]])\n",
        "                    height, width = image.shape[:2]\n",
        "                    image = cv2.warpAffine(image, trans_m, (width, height))\n",
        "\n",
        "                X[i] = image\n",
        "                y[i] = wheel\n",
        "            return X, y\n",
        "        \n",
        "        else:\n",
        "            for i, img in enumerate(X_list):\n",
        "                X[i] = img\n",
        "                \n",
        "            return X\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        X_list = [self.X[k] for k in indexes]\n",
        "        \n",
        "        if self.y is not None:\n",
        "            y_list = [self.y[k] for k in indexes]\n",
        "            X, y = self.__data_generation(X_list, y_list)\n",
        "            return X, y\n",
        "        else:\n",
        "            y_list = None\n",
        "            X = self.__data_generation(X_list, y_list)\n",
        "            return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CGHH2ozsYpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = '/content/drive/My Drive/before/sample1.dat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CecZLrJ4-EcG",
        "colab_type": "code",
        "outputId": "6c54533e-3a77-48fe-aea9-c60355d3d993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelpath = '/content/drive/My Drive/before/mymodel12.h5'\n",
        "model = get_model()\n",
        "train_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 100, 400, 3)       12        \n",
            "_________________________________________________________________\n",
            "mobilenetv2_0.60_100 (Model) (None, 4, 13, 1280)       958176    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 13, 1280)       5120      \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 964,589\n",
            "Trainable params: 939,847\n",
            "Non-trainable params: 24,742\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "156/155 [==============================] - 80s 515ms/step - loss: 0.1074 - sign_pred: 35.0705 - val_loss: 0.3352 - val_sign_pred: 31.5000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.33522, saving model to model-001.h5\n",
            "Epoch 2/200\n",
            "156/155 [==============================] - 62s 395ms/step - loss: 0.0162 - sign_pred: 39.3590 - val_loss: 0.2608 - val_sign_pred: 31.2857\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.33522 to 0.26083, saving model to model-002.h5\n",
            "Epoch 3/200\n",
            "156/155 [==============================] - 62s 395ms/step - loss: 0.0092 - sign_pred: 41.5641 - val_loss: 0.1063 - val_sign_pred: 30.7857\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.26083 to 0.10629, saving model to model-003.h5\n",
            "Epoch 4/200\n",
            "156/155 [==============================] - 62s 395ms/step - loss: 0.0072 - sign_pred: 42.5962 - val_loss: 0.0262 - val_sign_pred: 30.0714\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.10629 to 0.02620, saving model to model-004.h5\n",
            "Epoch 5/200\n",
            "156/155 [==============================] - 61s 394ms/step - loss: 0.0065 - sign_pred: 42.4936 - val_loss: 0.0231 - val_sign_pred: 29.6786\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02620 to 0.02307, saving model to model-005.h5\n",
            "Epoch 6/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0062 - sign_pred: 43.2692 - val_loss: 0.0240 - val_sign_pred: 30.5000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.02307\n",
            "Epoch 7/200\n",
            "156/155 [==============================] - 61s 392ms/step - loss: 0.0058 - sign_pred: 44.1474 - val_loss: 0.0130 - val_sign_pred: 31.1786\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.02307 to 0.01303, saving model to model-007.h5\n",
            "Epoch 8/200\n",
            "156/155 [==============================] - 61s 391ms/step - loss: 0.0055 - sign_pred: 43.9615 - val_loss: 0.0482 - val_sign_pred: 30.8214\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01303\n",
            "Epoch 9/200\n",
            "156/155 [==============================] - 61s 391ms/step - loss: 0.0055 - sign_pred: 44.3526 - val_loss: 0.0322 - val_sign_pred: 30.4643\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01303\n",
            "Epoch 10/200\n",
            "156/155 [==============================] - 61s 394ms/step - loss: 0.0054 - sign_pred: 44.8590 - val_loss: 0.0194 - val_sign_pred: 29.5714\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01303\n",
            "Epoch 11/200\n",
            "156/155 [==============================] - 62s 395ms/step - loss: 0.0052 - sign_pred: 45.3205 - val_loss: 0.0335 - val_sign_pred: 30.6786\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01303\n",
            "Epoch 12/200\n",
            "156/155 [==============================] - 61s 391ms/step - loss: 0.0052 - sign_pred: 45.2628 - val_loss: 0.0198 - val_sign_pred: 30.7143\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01303\n",
            "Epoch 13/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0050 - sign_pred: 45.5513 - val_loss: 0.0178 - val_sign_pred: 31.3571\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01303\n",
            "Epoch 14/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0051 - sign_pred: 45.5064 - val_loss: 0.0942 - val_sign_pred: 31.5357\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01303\n",
            "Epoch 15/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0048 - sign_pred: 46.3782 - val_loss: 0.0471 - val_sign_pred: 29.7857\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01303\n",
            "Epoch 16/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0047 - sign_pred: 46.8846 - val_loss: 0.0943 - val_sign_pred: 31.7143\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.01303\n",
            "Epoch 17/200\n",
            "156/155 [==============================] - 62s 396ms/step - loss: 0.0047 - sign_pred: 47.5321 - val_loss: 0.0977 - val_sign_pred: 31.5000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01303\n",
            "Epoch 18/200\n",
            "156/155 [==============================] - 61s 392ms/step - loss: 0.0047 - sign_pred: 47.6923 - val_loss: 0.0744 - val_sign_pred: 29.4643\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01303\n",
            "Epoch 19/200\n",
            "156/155 [==============================] - 61s 394ms/step - loss: 0.0045 - sign_pred: 47.4679 - val_loss: 0.1520 - val_sign_pred: 30.1786\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01303\n",
            "Epoch 20/200\n",
            "156/155 [==============================] - 62s 396ms/step - loss: 0.0043 - sign_pred: 48.8718 - val_loss: 0.0480 - val_sign_pred: 30.3214\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01303\n",
            "Epoch 21/200\n",
            "156/155 [==============================] - 61s 392ms/step - loss: 0.0042 - sign_pred: 48.5513 - val_loss: 0.0667 - val_sign_pred: 30.6786\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.01303\n",
            "Epoch 22/200\n",
            "156/155 [==============================] - 61s 393ms/step - loss: 0.0041 - sign_pred: 49.1154 - val_loss: 0.1431 - val_sign_pred: 31.2143\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01303\n",
            "Epoch 23/200\n",
            " 44/155 [=======>......................] - ETA: 41s - loss: 0.0037 - sign_pred: 50.3409"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tilGJ412pVwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(np.expand_dims(transform_image(cv2.imread('/content/drive/My Drive/before/20200505191234/20200505191234277788.jpg')), axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOFZjFOd9g5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = read_data(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHi_3ki-qM10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dg = DataGenerator(x, y, 64, (100, 400), 3)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i, (x, y) in enumerate(dg):\n",
        "    if(i <= 1):\n",
        "        x_first = x[0]\n",
        "        plt.title(y[0])\n",
        "        plt.imshow(x_first)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgYSs1PWxL5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (x, y) in enumerate(dg):\n",
        "    if(i <= 1):\n",
        "        x_first = x[0]\n",
        "        plt.title(y[0])\n",
        "        plt.imshow(x_first)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
